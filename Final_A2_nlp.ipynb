{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final A2_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nswZkbrmGm9b",
        "colab_type": "code",
        "outputId": "36d0b2ae-e50f-4758-9b0e-db519f42acfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten,Embedding\n",
        "from keras.layers import Activation, Conv1D, GlobalMaxPooling1D\n",
        "from keras import optimizers\n",
        "from keras import layers\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vpm1UvoGd_X",
        "colab_type": "code",
        "outputId": "8ec13bf3-bb6b-412a-e660-81b01ebe2565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "URL_Train= \"https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv\"\n",
        "\n",
        "#load data\n",
        "train=pd.read_csv(URL_Train,sep='\\t')\n",
        "print(len(train))\n",
        "train.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "156060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omK1ZwGUzm7y",
        "colab_type": "code",
        "outputId": "9e48b260-f0ba-4d5f-f733-60225350492f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "phrase = train['Phrase']\n",
        "sentiment = train['Sentiment']\n",
        "sentiment.value_counts().plot(kind='bar')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f16df378390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlqfVfa7Gv0_",
        "colab_type": "code",
        "outputId": "1978e517-b4f0-46ac-82e2-8078de612873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "fullSentences = []\n",
        "curSentence = 0\n",
        "for i in range(train.shape[0]):\n",
        "  if train['SentenceId'][i]> curSentence:\n",
        "    fullSentences.append((train['Phrase'][i], train['Sentiment'][i]))\n",
        "    curSentence = curSentence +1\n",
        "\n",
        "# put data into a df\n",
        "fullSentDf = pd.DataFrame(fullSentences,\n",
        "                                columns=['Phrase', 'Sentiment'])\n",
        "print(fullSentDf['Sentiment'].value_counts())\n",
        "print(fullSentDf['Phrase'][1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3    2325\n",
            "1    2203\n",
            "2    1659\n",
            "4    1282\n",
            "0    1075\n",
            "Name: Sentiment, dtype: int64\n",
            "This quiet , introspective and entertaining independent is worth seeking .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcdLYu-jbPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "documents = []\n",
        "#convert data into format for the previous labs\n",
        "\n",
        "#use full dataset\n",
        "#for i in range(data.shape[0]):\n",
        "#  tmpWords = word_tokenize(data['Phrase'][i])\n",
        "#  documents.append((tmpWords, data['Sentiment'][i]))\n",
        "\n",
        "# Use only complete sentences\n",
        "for i in range(fullSentDf.shape[0]):\n",
        "  tmpWords = word_tokenize(fullSentDf['Phrase'][i])\n",
        "  documents.append((tmpWords, fullSentDf['Sentiment'][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVDh_shvG6G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "StopWords = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = True\n",
        "useStemming = True\n",
        "useLemma = False\n",
        "removePuncs = True\n",
        "# print(StopWords)\n",
        "\n",
        "for l in range(len(documents)): #For each review docu-ment\n",
        "  # print(l)\n",
        "  label = documents[l][1] #Save review label\n",
        "  tmpReview = [] #Placeholder list for new review\n",
        "  # train_new=[]\n",
        "  for w in documents[l][0]: #For each word this is review\n",
        "    newWord = w #Set newWork to be the updated word\n",
        "    if remove_stopwords and (w in StopWords):#if the word is a stopword \n",
        "      continue #skip the word and don’t had it to the normalized review\n",
        "    if removePuncs and (w in punctuations):#if the word is a punc\n",
        "      continue #skip the word and don’t had it to the normalized review\n",
        "    if useStemming: #if useStemming is set to True\n",
        "      #Keep one stemmer commented out\n",
        "      #newWord = porter.stem(newWord) #User porter stemmer\n",
        "      newWord = lancaster.stem(newWord) #Use Lancaster stemmer\n",
        "    if useLemma:\n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "    tmpReview.append(newWord) #Add normalized word to the tmp review\n",
        "  documents[l] = (' '.join(tmpReview), label)\n",
        "# print(documents[2]) #Update the reviews list with clean review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpSUItyNInCu",
        "colab_type": "code",
        "outputId": "257ade67-23a1-4e91-b0a1-a14a83d6a1c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "## Splitting the training and testing data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train['Phrase'], \n",
        "                                                    train['Sentiment'], \n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=2003)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242,)\n",
            "(46818,)\n",
            "(109242,)\n",
            "(46818,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZBuYahxNxWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "NB_WORDS = 5000\n",
        "tk = Tokenizer(num_words=NB_WORDS,\n",
        "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "               lower=True,\n",
        "               split=\" \")\n",
        "tk.fit_on_texts(X_train)\n",
        "\n",
        "# TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", \n",
        "                                   ngram_range=(1, 1), \n",
        "                                   max_features = 5000)\n",
        "\n",
        "train_tfid = tfidf_vectorizer.fit_transform(X_train)\n",
        "train_tfid = np.array(train_tfid.toarray())\n",
        "\n",
        "test_tfid = tfidf_vectorizer.fit_transform(X_test)\n",
        "test_tfid = np.array(test_tfid.toarray())\n",
        "\n",
        "X_train_seq = tk.texts_to_sequences(X_train)\n",
        "X_test_seq = tk.texts_to_sequences(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbGJWp9TOiaz",
        "colab_type": "code",
        "outputId": "a2977202-724c-4d93-f193-fc2a0ad7c041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "seq_lengths = X_train.apply(lambda x: len(x.split(' ')))\n",
        "seq_lengths.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    109242.000000\n",
              "mean          7.194595\n",
              "std           7.011804\n",
              "min           1.000000\n",
              "25%           2.000000\n",
              "50%           5.000000\n",
              "75%          10.000000\n",
              "max          52.000000\n",
              "Name: Phrase, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5wb7ZXfOoxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 51\n",
        "X_train_seq_trunc = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
        "X_test_seq_trunc = pad_sequences(X_test_seq, maxlen=MAX_LEN)\n",
        "# X_train_seq_trunc[15]  # Example of padded sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ayXwO61OtW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_le = le.fit_transform(y_train)\n",
        "y_test_le = le.transform(y_test)\n",
        "y_train_oh = to_categorical(y_train_le)\n",
        "y_test_oh = to_categorical(y_test_le)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW_WEypqVgrP",
        "colab_type": "code",
        "outputId": "8d6fc0f9-1b70-42ed-ac82-d594fa79dc39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train_oh.shape)\n",
        "print(y_test_oh.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242,)\n",
            "(46818,)\n",
            "(109242, 5)\n",
            "(46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYjejWJmPkx1",
        "colab_type": "code",
        "outputId": "c57174da-2bb0-4681-d1bf-f6db55dfb0ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Splitting the validation data\n",
        "X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_seq_trunc, \n",
        "                                                                      y_train_oh, \n",
        "                                                                      test_size=0.1, \n",
        "                                                                      random_state=2003)\n",
        "\n",
        "assert X_valid_emb.shape[0] == y_valid_emb.shape[0]\n",
        "assert X_train_emb.shape[0] == y_train_emb.shape[0]\n",
        "\n",
        "print('Shape of validation set:',X_valid_emb.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of validation set: (10925, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQNfV1UyccTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions used to get the performnce of the model\n",
        "def recall_m(y_true,y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true*y_pred,0,1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0,1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true*y_pred, 0,1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "  precision= precision_m(y_true, y_pred)\n",
        "  recall= recall_m(y_true, y_pred)\n",
        "  return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDI4u-7ZP5GF",
        "colab_type": "code",
        "outputId": "3e6884bd-ae1d-4fba-b28a-864d65519ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "##### Model ######\n",
        "Model = models.Sequential()\n",
        "Model.add(layers.Embedding(NB_WORDS, 5, input_length=MAX_LEN))\n",
        "Model.add(Conv1D(filters=100, kernel_size=2, activation= 'relu'))\n",
        "Model.add(MaxPooling1D(pool_size=2))\n",
        "Model.add(Conv1D(filters=100, kernel_size=2, activation= 'relu'))\n",
        "Model.add(MaxPooling1D(pool_size=2))\n",
        "Model.add(layers.Flatten())\n",
        "Model.add(layers.Dense(5, activation='softmax'))\n",
        "Model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 51, 5)             25000     \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 50, 100)           1100      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 25, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 24, 100)           20100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 12, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1200)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 6005      \n",
            "=================================================================\n",
            "Total params: 52,205\n",
            "Trainable params: 52,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H0-jawJkMdK",
        "colab_type": "code",
        "outputId": "bd271741-1619-4796-849b-e9b26d87b8f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Save the trained model\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "Model.save('1093483_SentimentAnalysis.h5')\n",
        "Model_file = drive.CreateFile({'title' : '1093483_SentimentAnalysis.h5'})                       \n",
        "Model_file.SetContentFile('1093483_SentimentAnalysis.h5')                       \n",
        "Model_file.Upload()\n",
        "\n",
        "# download to google drive                       \n",
        "drive.CreateFile({'id': Model_file.get('id')})"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1J_6Oyu50QGE-AC7svA1aoEm2-7xkRxSR'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR0f6kROQMgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ade3d8fe-937f-42d5-bfa7-863d0b9527f6"
      },
      "source": [
        "# Initializing the parameters\n",
        "lr=1e-4\n",
        "decay=1e-4\n",
        "num_epochs=100\n",
        "adm = optimizers.Adam(lr=lr, decay=decay)\n",
        "\n",
        "# Compile & Fit the model\n",
        "Model.compile(optimizer=adm,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy',f1_m,precision_m,recall_m])\n",
        "\n",
        "t1=time.time()\n",
        "history_train = Model.fit(X_train_emb,\n",
        "                    y_train_emb,\n",
        "                    epochs=num_epochs,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(X_valid_emb,y_valid_emb))\n",
        "t2=time.time()\n",
        "t3=t2-t1\n",
        "print('Training Time:',np.round(t3,2),'seconds')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 98317 samples, validate on 10925 samples\n",
            "Epoch 1/100\n",
            "98317/98317 [==============================] - 10s 104us/step - loss: 1.2894 - acc: 0.5121 - f1_m: 0.4001 - precision_m: 0.4927 - recall_m: 0.3414 - val_loss: 1.2389 - val_acc: 0.5051 - val_f1_m: 0.4515 - val_precision_m: 0.6354 - val_recall_m: 0.3511\n",
            "Epoch 2/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.2104 - acc: 0.5190 - f1_m: 0.4753 - precision_m: 0.6427 - recall_m: 0.3780 - val_loss: 1.2076 - val_acc: 0.5149 - val_f1_m: 0.4706 - val_precision_m: 0.6564 - val_recall_m: 0.3677\n",
            "Epoch 3/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.1744 - acc: 0.5300 - f1_m: 0.4876 - precision_m: 0.6769 - recall_m: 0.3820 - val_loss: 1.1691 - val_acc: 0.5305 - val_f1_m: 0.4782 - val_precision_m: 0.6946 - val_recall_m: 0.3658\n",
            "Epoch 4/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.1354 - acc: 0.5459 - f1_m: 0.5060 - precision_m: 0.7042 - recall_m: 0.3959 - val_loss: 1.1407 - val_acc: 0.5447 - val_f1_m: 0.4967 - val_precision_m: 0.7010 - val_recall_m: 0.3855\n",
            "Epoch 5/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.1102 - acc: 0.5581 - f1_m: 0.5166 - precision_m: 0.7156 - recall_m: 0.4051 - val_loss: 1.1270 - val_acc: 0.5486 - val_f1_m: 0.5099 - val_precision_m: 0.6906 - val_recall_m: 0.4050\n",
            "Epoch 6/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.0951 - acc: 0.5658 - f1_m: 0.5227 - precision_m: 0.7174 - recall_m: 0.4121 - val_loss: 1.1164 - val_acc: 0.5540 - val_f1_m: 0.5134 - val_precision_m: 0.6898 - val_recall_m: 0.4098\n",
            "Epoch 7/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.0844 - acc: 0.5709 - f1_m: 0.5276 - precision_m: 0.7181 - recall_m: 0.4179 - val_loss: 1.1091 - val_acc: 0.5597 - val_f1_m: 0.5168 - val_precision_m: 0.6927 - val_recall_m: 0.4131\n",
            "Epoch 8/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.0756 - acc: 0.5759 - f1_m: 0.5317 - precision_m: 0.7176 - recall_m: 0.4233 - val_loss: 1.1001 - val_acc: 0.5666 - val_f1_m: 0.5173 - val_precision_m: 0.6994 - val_recall_m: 0.4114\n",
            "Epoch 9/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.0679 - acc: 0.5794 - f1_m: 0.5351 - precision_m: 0.7160 - recall_m: 0.4281 - val_loss: 1.0949 - val_acc: 0.5693 - val_f1_m: 0.5201 - val_precision_m: 0.6960 - val_recall_m: 0.4160\n",
            "Epoch 10/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 1.0609 - acc: 0.5825 - f1_m: 0.5380 - precision_m: 0.7152 - recall_m: 0.4321 - val_loss: 1.0890 - val_acc: 0.5713 - val_f1_m: 0.5241 - val_precision_m: 0.6943 - val_recall_m: 0.4219\n",
            "Epoch 11/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0542 - acc: 0.5859 - f1_m: 0.5412 - precision_m: 0.7132 - recall_m: 0.4369 - val_loss: 1.0834 - val_acc: 0.5757 - val_f1_m: 0.5244 - val_precision_m: 0.6925 - val_recall_m: 0.4228\n",
            "Epoch 12/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0477 - acc: 0.5898 - f1_m: 0.5439 - precision_m: 0.7117 - recall_m: 0.4410 - val_loss: 1.0784 - val_acc: 0.5757 - val_f1_m: 0.5295 - val_precision_m: 0.6885 - val_recall_m: 0.4309\n",
            "Epoch 13/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0415 - acc: 0.5926 - f1_m: 0.5480 - precision_m: 0.7097 - recall_m: 0.4472 - val_loss: 1.0731 - val_acc: 0.5800 - val_f1_m: 0.5319 - val_precision_m: 0.6860 - val_recall_m: 0.4351\n",
            "Epoch 14/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0354 - acc: 0.5949 - f1_m: 0.5517 - precision_m: 0.7073 - recall_m: 0.4531 - val_loss: 1.0676 - val_acc: 0.5832 - val_f1_m: 0.5327 - val_precision_m: 0.6835 - val_recall_m: 0.4372\n",
            "Epoch 15/100\n",
            "98317/98317 [==============================] - 3s 36us/step - loss: 1.0295 - acc: 0.5981 - f1_m: 0.5544 - precision_m: 0.7052 - recall_m: 0.4575 - val_loss: 1.0633 - val_acc: 0.5835 - val_f1_m: 0.5345 - val_precision_m: 0.6826 - val_recall_m: 0.4400\n",
            "Epoch 16/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0239 - acc: 0.6000 - f1_m: 0.5569 - precision_m: 0.7036 - recall_m: 0.4617 - val_loss: 1.0595 - val_acc: 0.5834 - val_f1_m: 0.5413 - val_precision_m: 0.6766 - val_recall_m: 0.4517\n",
            "Epoch 17/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0185 - acc: 0.6024 - f1_m: 0.5600 - precision_m: 0.7008 - recall_m: 0.4671 - val_loss: 1.0547 - val_acc: 0.5854 - val_f1_m: 0.5416 - val_precision_m: 0.6761 - val_recall_m: 0.4524\n",
            "Epoch 18/100\n",
            "98317/98317 [==============================] - 4s 37us/step - loss: 1.0133 - acc: 0.6045 - f1_m: 0.5623 - precision_m: 0.6991 - recall_m: 0.4710 - val_loss: 1.0505 - val_acc: 0.5859 - val_f1_m: 0.5447 - val_precision_m: 0.6737 - val_recall_m: 0.4578\n",
            "Epoch 19/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0082 - acc: 0.6059 - f1_m: 0.5653 - precision_m: 0.6974 - recall_m: 0.4759 - val_loss: 1.0467 - val_acc: 0.5859 - val_f1_m: 0.5457 - val_precision_m: 0.6741 - val_recall_m: 0.4590\n",
            "Epoch 20/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 1.0033 - acc: 0.6076 - f1_m: 0.5671 - precision_m: 0.6958 - recall_m: 0.4792 - val_loss: 1.0429 - val_acc: 0.5871 - val_f1_m: 0.5468 - val_precision_m: 0.6711 - val_recall_m: 0.4620\n",
            "Epoch 21/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9987 - acc: 0.6091 - f1_m: 0.5690 - precision_m: 0.6938 - recall_m: 0.4829 - val_loss: 1.0385 - val_acc: 0.5902 - val_f1_m: 0.5435 - val_precision_m: 0.6707 - val_recall_m: 0.4575\n",
            "Epoch 22/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9941 - acc: 0.6109 - f1_m: 0.5712 - precision_m: 0.6935 - recall_m: 0.4864 - val_loss: 1.0351 - val_acc: 0.5910 - val_f1_m: 0.5479 - val_precision_m: 0.6693 - val_recall_m: 0.4644\n",
            "Epoch 23/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9897 - acc: 0.6127 - f1_m: 0.5734 - precision_m: 0.6915 - recall_m: 0.4905 - val_loss: 1.0319 - val_acc: 0.5915 - val_f1_m: 0.5508 - val_precision_m: 0.6683 - val_recall_m: 0.4691\n",
            "Epoch 24/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9855 - acc: 0.6135 - f1_m: 0.5753 - precision_m: 0.6911 - recall_m: 0.4934 - val_loss: 1.0281 - val_acc: 0.5918 - val_f1_m: 0.5519 - val_precision_m: 0.6664 - val_recall_m: 0.4716\n",
            "Epoch 25/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9814 - acc: 0.6152 - f1_m: 0.5771 - precision_m: 0.6905 - recall_m: 0.4964 - val_loss: 1.0247 - val_acc: 0.5929 - val_f1_m: 0.5537 - val_precision_m: 0.6638 - val_recall_m: 0.4755\n",
            "Epoch 26/100\n",
            "98317/98317 [==============================] - 4s 37us/step - loss: 0.9773 - acc: 0.6162 - f1_m: 0.5791 - precision_m: 0.6898 - recall_m: 0.4998 - val_loss: 1.0220 - val_acc: 0.5927 - val_f1_m: 0.5555 - val_precision_m: 0.6641 - val_recall_m: 0.4781\n",
            "Epoch 27/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9732 - acc: 0.6179 - f1_m: 0.5805 - precision_m: 0.6897 - recall_m: 0.5017 - val_loss: 1.0187 - val_acc: 0.5953 - val_f1_m: 0.5596 - val_precision_m: 0.6626 - val_recall_m: 0.4849\n",
            "Epoch 28/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9693 - acc: 0.6190 - f1_m: 0.5821 - precision_m: 0.6884 - recall_m: 0.5048 - val_loss: 1.0168 - val_acc: 0.5944 - val_f1_m: 0.5608 - val_precision_m: 0.6612 - val_recall_m: 0.4875\n",
            "Epoch 29/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9653 - acc: 0.6204 - f1_m: 0.5838 - precision_m: 0.6889 - recall_m: 0.5071 - val_loss: 1.0121 - val_acc: 0.5984 - val_f1_m: 0.5615 - val_precision_m: 0.6632 - val_recall_m: 0.4874\n",
            "Epoch 30/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9615 - acc: 0.6216 - f1_m: 0.5857 - precision_m: 0.6880 - recall_m: 0.5106 - val_loss: 1.0087 - val_acc: 0.5984 - val_f1_m: 0.5625 - val_precision_m: 0.6646 - val_recall_m: 0.4881\n",
            "Epoch 31/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9576 - acc: 0.6229 - f1_m: 0.5873 - precision_m: 0.6881 - recall_m: 0.5129 - val_loss: 1.0070 - val_acc: 0.5993 - val_f1_m: 0.5675 - val_precision_m: 0.6602 - val_recall_m: 0.4981\n",
            "Epoch 32/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9539 - acc: 0.6243 - f1_m: 0.5890 - precision_m: 0.6875 - recall_m: 0.5158 - val_loss: 1.0039 - val_acc: 0.6007 - val_f1_m: 0.5675 - val_precision_m: 0.6593 - val_recall_m: 0.4987\n",
            "Epoch 33/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9501 - acc: 0.6254 - f1_m: 0.5913 - precision_m: 0.6872 - recall_m: 0.5195 - val_loss: 1.0009 - val_acc: 0.6011 - val_f1_m: 0.5695 - val_precision_m: 0.6587 - val_recall_m: 0.5021\n",
            "Epoch 34/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.9466 - acc: 0.6268 - f1_m: 0.5931 - precision_m: 0.6872 - recall_m: 0.5222 - val_loss: 0.9972 - val_acc: 0.6019 - val_f1_m: 0.5685 - val_precision_m: 0.6589 - val_recall_m: 0.5004\n",
            "Epoch 35/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9432 - acc: 0.6282 - f1_m: 0.5944 - precision_m: 0.6872 - recall_m: 0.5243 - val_loss: 0.9948 - val_acc: 0.6027 - val_f1_m: 0.5709 - val_precision_m: 0.6594 - val_recall_m: 0.5038\n",
            "Epoch 36/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9396 - acc: 0.6294 - f1_m: 0.5956 - precision_m: 0.6864 - recall_m: 0.5266 - val_loss: 0.9918 - val_acc: 0.6043 - val_f1_m: 0.5724 - val_precision_m: 0.6580 - val_recall_m: 0.5070\n",
            "Epoch 37/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9362 - acc: 0.6308 - f1_m: 0.5976 - precision_m: 0.6869 - recall_m: 0.5293 - val_loss: 0.9893 - val_acc: 0.6051 - val_f1_m: 0.5728 - val_precision_m: 0.6566 - val_recall_m: 0.5085\n",
            "Epoch 38/100\n",
            "98317/98317 [==============================] - 4s 38us/step - loss: 0.9329 - acc: 0.6321 - f1_m: 0.5992 - precision_m: 0.6871 - recall_m: 0.5318 - val_loss: 0.9866 - val_acc: 0.6065 - val_f1_m: 0.5741 - val_precision_m: 0.6570 - val_recall_m: 0.5102\n",
            "Epoch 39/100\n",
            "98317/98317 [==============================] - 4s 38us/step - loss: 0.9297 - acc: 0.6333 - f1_m: 0.6008 - precision_m: 0.6870 - recall_m: 0.5343 - val_loss: 0.9837 - val_acc: 0.6070 - val_f1_m: 0.5747 - val_precision_m: 0.6585 - val_recall_m: 0.5103\n",
            "Epoch 40/100\n",
            "98317/98317 [==============================] - 4s 37us/step - loss: 0.9267 - acc: 0.6340 - f1_m: 0.6025 - precision_m: 0.6876 - recall_m: 0.5367 - val_loss: 0.9813 - val_acc: 0.6078 - val_f1_m: 0.5761 - val_precision_m: 0.6590 - val_recall_m: 0.5122\n",
            "Epoch 41/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9236 - acc: 0.6354 - f1_m: 0.6041 - precision_m: 0.6877 - recall_m: 0.5392 - val_loss: 0.9798 - val_acc: 0.6088 - val_f1_m: 0.5792 - val_precision_m: 0.6555 - val_recall_m: 0.5193\n",
            "Epoch 42/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9208 - acc: 0.6359 - f1_m: 0.6053 - precision_m: 0.6875 - recall_m: 0.5412 - val_loss: 0.9775 - val_acc: 0.6094 - val_f1_m: 0.5793 - val_precision_m: 0.6565 - val_recall_m: 0.5187\n",
            "Epoch 43/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9179 - acc: 0.6374 - f1_m: 0.6071 - precision_m: 0.6878 - recall_m: 0.5438 - val_loss: 0.9749 - val_acc: 0.6114 - val_f1_m: 0.5813 - val_precision_m: 0.6589 - val_recall_m: 0.5205\n",
            "Epoch 44/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.9151 - acc: 0.6380 - f1_m: 0.6084 - precision_m: 0.6887 - recall_m: 0.5455 - val_loss: 0.9733 - val_acc: 0.6114 - val_f1_m: 0.5834 - val_precision_m: 0.6575 - val_recall_m: 0.5248\n",
            "Epoch 45/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.9124 - acc: 0.6391 - f1_m: 0.6099 - precision_m: 0.6891 - recall_m: 0.5476 - val_loss: 0.9712 - val_acc: 0.6123 - val_f1_m: 0.5814 - val_precision_m: 0.6598 - val_recall_m: 0.5200\n",
            "Epoch 46/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9100 - acc: 0.6400 - f1_m: 0.6115 - precision_m: 0.6894 - recall_m: 0.5498 - val_loss: 0.9692 - val_acc: 0.6134 - val_f1_m: 0.5842 - val_precision_m: 0.6600 - val_recall_m: 0.5244\n",
            "Epoch 47/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9074 - acc: 0.6409 - f1_m: 0.6124 - precision_m: 0.6899 - recall_m: 0.5509 - val_loss: 0.9678 - val_acc: 0.6144 - val_f1_m: 0.5838 - val_precision_m: 0.6586 - val_recall_m: 0.5247\n",
            "Epoch 48/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9050 - acc: 0.6419 - f1_m: 0.6140 - precision_m: 0.6906 - recall_m: 0.5531 - val_loss: 0.9655 - val_acc: 0.6143 - val_f1_m: 0.5860 - val_precision_m: 0.6602 - val_recall_m: 0.5272\n",
            "Epoch 49/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9028 - acc: 0.6424 - f1_m: 0.6151 - precision_m: 0.6902 - recall_m: 0.5552 - val_loss: 0.9645 - val_acc: 0.6152 - val_f1_m: 0.5858 - val_precision_m: 0.6600 - val_recall_m: 0.5270\n",
            "Epoch 50/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.9005 - acc: 0.6432 - f1_m: 0.6164 - precision_m: 0.6916 - recall_m: 0.5564 - val_loss: 0.9625 - val_acc: 0.6158 - val_f1_m: 0.5870 - val_precision_m: 0.6597 - val_recall_m: 0.5292\n",
            "Epoch 51/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8984 - acc: 0.6442 - f1_m: 0.6169 - precision_m: 0.6911 - recall_m: 0.5576 - val_loss: 0.9611 - val_acc: 0.6168 - val_f1_m: 0.5871 - val_precision_m: 0.6597 - val_recall_m: 0.5293\n",
            "Epoch 52/100\n",
            "98317/98317 [==============================] - 3s 36us/step - loss: 0.8964 - acc: 0.6449 - f1_m: 0.6177 - precision_m: 0.6918 - recall_m: 0.5584 - val_loss: 0.9608 - val_acc: 0.6157 - val_f1_m: 0.5921 - val_precision_m: 0.6581 - val_recall_m: 0.5386\n",
            "Epoch 53/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8944 - acc: 0.6460 - f1_m: 0.6190 - precision_m: 0.6921 - recall_m: 0.5603 - val_loss: 0.9591 - val_acc: 0.6169 - val_f1_m: 0.5904 - val_precision_m: 0.6577 - val_recall_m: 0.5359\n",
            "Epoch 54/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8925 - acc: 0.6470 - f1_m: 0.6200 - precision_m: 0.6925 - recall_m: 0.5617 - val_loss: 0.9578 - val_acc: 0.6173 - val_f1_m: 0.5895 - val_precision_m: 0.6587 - val_recall_m: 0.5339\n",
            "Epoch 55/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8907 - acc: 0.6473 - f1_m: 0.6208 - precision_m: 0.6933 - recall_m: 0.5626 - val_loss: 0.9559 - val_acc: 0.6197 - val_f1_m: 0.5938 - val_precision_m: 0.6605 - val_recall_m: 0.5398\n",
            "Epoch 56/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8889 - acc: 0.6481 - f1_m: 0.6222 - precision_m: 0.6929 - recall_m: 0.5649 - val_loss: 0.9546 - val_acc: 0.6198 - val_f1_m: 0.5931 - val_precision_m: 0.6616 - val_recall_m: 0.5378\n",
            "Epoch 57/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8872 - acc: 0.6489 - f1_m: 0.6225 - precision_m: 0.6940 - recall_m: 0.5648 - val_loss: 0.9540 - val_acc: 0.6195 - val_f1_m: 0.5957 - val_precision_m: 0.6633 - val_recall_m: 0.5410\n",
            "Epoch 58/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8856 - acc: 0.6496 - f1_m: 0.6236 - precision_m: 0.6941 - recall_m: 0.5667 - val_loss: 0.9527 - val_acc: 0.6211 - val_f1_m: 0.5948 - val_precision_m: 0.6635 - val_recall_m: 0.5393\n",
            "Epoch 59/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8840 - acc: 0.6504 - f1_m: 0.6244 - precision_m: 0.6942 - recall_m: 0.5678 - val_loss: 0.9514 - val_acc: 0.6222 - val_f1_m: 0.5960 - val_precision_m: 0.6628 - val_recall_m: 0.5418\n",
            "Epoch 60/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8825 - acc: 0.6509 - f1_m: 0.6250 - precision_m: 0.6944 - recall_m: 0.5686 - val_loss: 0.9504 - val_acc: 0.6222 - val_f1_m: 0.5953 - val_precision_m: 0.6639 - val_recall_m: 0.5399\n",
            "Epoch 61/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8810 - acc: 0.6517 - f1_m: 0.6258 - precision_m: 0.6955 - recall_m: 0.5693 - val_loss: 0.9491 - val_acc: 0.6250 - val_f1_m: 0.5967 - val_precision_m: 0.6646 - val_recall_m: 0.5417\n",
            "Epoch 62/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8796 - acc: 0.6524 - f1_m: 0.6272 - precision_m: 0.6954 - recall_m: 0.5717 - val_loss: 0.9494 - val_acc: 0.6216 - val_f1_m: 0.5980 - val_precision_m: 0.6630 - val_recall_m: 0.5449\n",
            "Epoch 63/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8782 - acc: 0.6530 - f1_m: 0.6277 - precision_m: 0.6962 - recall_m: 0.5719 - val_loss: 0.9475 - val_acc: 0.6254 - val_f1_m: 0.5972 - val_precision_m: 0.6660 - val_recall_m: 0.5417\n",
            "Epoch 64/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8769 - acc: 0.6542 - f1_m: 0.6281 - precision_m: 0.6958 - recall_m: 0.5728 - val_loss: 0.9472 - val_acc: 0.6232 - val_f1_m: 0.5998 - val_precision_m: 0.6616 - val_recall_m: 0.5489\n",
            "Epoch 65/100\n",
            "98317/98317 [==============================] - 3s 36us/step - loss: 0.8756 - acc: 0.6543 - f1_m: 0.6296 - precision_m: 0.6967 - recall_m: 0.5747 - val_loss: 0.9458 - val_acc: 0.6238 - val_f1_m: 0.5985 - val_precision_m: 0.6625 - val_recall_m: 0.5461\n",
            "Epoch 66/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8743 - acc: 0.6547 - f1_m: 0.6299 - precision_m: 0.6966 - recall_m: 0.5752 - val_loss: 0.9458 - val_acc: 0.6239 - val_f1_m: 0.6001 - val_precision_m: 0.6605 - val_recall_m: 0.5501\n",
            "Epoch 67/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8732 - acc: 0.6555 - f1_m: 0.6307 - precision_m: 0.6969 - recall_m: 0.5764 - val_loss: 0.9447 - val_acc: 0.6243 - val_f1_m: 0.6011 - val_precision_m: 0.6646 - val_recall_m: 0.5491\n",
            "Epoch 68/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8720 - acc: 0.6560 - f1_m: 0.6312 - precision_m: 0.6968 - recall_m: 0.5774 - val_loss: 0.9436 - val_acc: 0.6260 - val_f1_m: 0.6008 - val_precision_m: 0.6636 - val_recall_m: 0.5492\n",
            "Epoch 69/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8709 - acc: 0.6558 - f1_m: 0.6314 - precision_m: 0.6966 - recall_m: 0.5778 - val_loss: 0.9430 - val_acc: 0.6246 - val_f1_m: 0.6010 - val_precision_m: 0.6639 - val_recall_m: 0.5492\n",
            "Epoch 70/100\n",
            "98317/98317 [==============================] - 3s 36us/step - loss: 0.8698 - acc: 0.6563 - f1_m: 0.6317 - precision_m: 0.6970 - recall_m: 0.5779 - val_loss: 0.9430 - val_acc: 0.6244 - val_f1_m: 0.6021 - val_precision_m: 0.6603 - val_recall_m: 0.5535\n",
            "Epoch 71/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8688 - acc: 0.6569 - f1_m: 0.6330 - precision_m: 0.6974 - recall_m: 0.5800 - val_loss: 0.9415 - val_acc: 0.6256 - val_f1_m: 0.6018 - val_precision_m: 0.6628 - val_recall_m: 0.5514\n",
            "Epoch 72/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8677 - acc: 0.6572 - f1_m: 0.6332 - precision_m: 0.6973 - recall_m: 0.5803 - val_loss: 0.9409 - val_acc: 0.6267 - val_f1_m: 0.6024 - val_precision_m: 0.6634 - val_recall_m: 0.5519\n",
            "Epoch 73/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8668 - acc: 0.6573 - f1_m: 0.6332 - precision_m: 0.6968 - recall_m: 0.5807 - val_loss: 0.9401 - val_acc: 0.6265 - val_f1_m: 0.6015 - val_precision_m: 0.6635 - val_recall_m: 0.5505\n",
            "Epoch 74/100\n",
            "98317/98317 [==============================] - 3s 36us/step - loss: 0.8658 - acc: 0.6582 - f1_m: 0.6343 - precision_m: 0.6978 - recall_m: 0.5819 - val_loss: 0.9398 - val_acc: 0.6259 - val_f1_m: 0.6026 - val_precision_m: 0.6629 - val_recall_m: 0.5526\n",
            "Epoch 75/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8649 - acc: 0.6582 - f1_m: 0.6346 - precision_m: 0.6978 - recall_m: 0.5823 - val_loss: 0.9389 - val_acc: 0.6261 - val_f1_m: 0.6024 - val_precision_m: 0.6638 - val_recall_m: 0.5517\n",
            "Epoch 76/100\n",
            "98317/98317 [==============================] - 4s 37us/step - loss: 0.8640 - acc: 0.6588 - f1_m: 0.6354 - precision_m: 0.6983 - recall_m: 0.5833 - val_loss: 0.9388 - val_acc: 0.6257 - val_f1_m: 0.6032 - val_precision_m: 0.6628 - val_recall_m: 0.5539\n",
            "Epoch 77/100\n",
            "98317/98317 [==============================] - 4s 38us/step - loss: 0.8631 - acc: 0.6590 - f1_m: 0.6357 - precision_m: 0.6979 - recall_m: 0.5840 - val_loss: 0.9378 - val_acc: 0.6267 - val_f1_m: 0.6022 - val_precision_m: 0.6639 - val_recall_m: 0.5513\n",
            "Epoch 78/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8622 - acc: 0.6593 - f1_m: 0.6363 - precision_m: 0.6986 - recall_m: 0.5846 - val_loss: 0.9375 - val_acc: 0.6265 - val_f1_m: 0.6043 - val_precision_m: 0.6642 - val_recall_m: 0.5548\n",
            "Epoch 79/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8614 - acc: 0.6596 - f1_m: 0.6363 - precision_m: 0.6984 - recall_m: 0.5849 - val_loss: 0.9372 - val_acc: 0.6267 - val_f1_m: 0.6039 - val_precision_m: 0.6617 - val_recall_m: 0.5557\n",
            "Epoch 80/100\n",
            "98317/98317 [==============================] - 3s 36us/step - loss: 0.8606 - acc: 0.6599 - f1_m: 0.6367 - precision_m: 0.6984 - recall_m: 0.5854 - val_loss: 0.9365 - val_acc: 0.6272 - val_f1_m: 0.6048 - val_precision_m: 0.6640 - val_recall_m: 0.5556\n",
            "Epoch 81/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8598 - acc: 0.6605 - f1_m: 0.6371 - precision_m: 0.6986 - recall_m: 0.5859 - val_loss: 0.9360 - val_acc: 0.6274 - val_f1_m: 0.6046 - val_precision_m: 0.6630 - val_recall_m: 0.5560\n",
            "Epoch 82/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8591 - acc: 0.6606 - f1_m: 0.6376 - precision_m: 0.6988 - recall_m: 0.5867 - val_loss: 0.9360 - val_acc: 0.6273 - val_f1_m: 0.6058 - val_precision_m: 0.6626 - val_recall_m: 0.5583\n",
            "Epoch 83/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8584 - acc: 0.6605 - f1_m: 0.6380 - precision_m: 0.6987 - recall_m: 0.5875 - val_loss: 0.9347 - val_acc: 0.6291 - val_f1_m: 0.6066 - val_precision_m: 0.6673 - val_recall_m: 0.5565\n",
            "Epoch 84/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8576 - acc: 0.6608 - f1_m: 0.6383 - precision_m: 0.6989 - recall_m: 0.5878 - val_loss: 0.9348 - val_acc: 0.6274 - val_f1_m: 0.6055 - val_precision_m: 0.6639 - val_recall_m: 0.5569\n",
            "Epoch 85/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8569 - acc: 0.6609 - f1_m: 0.6386 - precision_m: 0.6990 - recall_m: 0.5882 - val_loss: 0.9343 - val_acc: 0.6285 - val_f1_m: 0.6055 - val_precision_m: 0.6632 - val_recall_m: 0.5574\n",
            "Epoch 86/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8562 - acc: 0.6616 - f1_m: 0.6394 - precision_m: 0.6999 - recall_m: 0.5890 - val_loss: 0.9344 - val_acc: 0.6281 - val_f1_m: 0.6063 - val_precision_m: 0.6622 - val_recall_m: 0.5594\n",
            "Epoch 87/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8556 - acc: 0.6617 - f1_m: 0.6396 - precision_m: 0.6997 - recall_m: 0.5894 - val_loss: 0.9341 - val_acc: 0.6280 - val_f1_m: 0.6066 - val_precision_m: 0.6632 - val_recall_m: 0.5593\n",
            "Epoch 88/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8550 - acc: 0.6617 - f1_m: 0.6397 - precision_m: 0.6991 - recall_m: 0.5901 - val_loss: 0.9332 - val_acc: 0.6276 - val_f1_m: 0.6072 - val_precision_m: 0.6644 - val_recall_m: 0.5594\n",
            "Epoch 89/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8543 - acc: 0.6623 - f1_m: 0.6400 - precision_m: 0.6998 - recall_m: 0.5899 - val_loss: 0.9330 - val_acc: 0.6272 - val_f1_m: 0.6076 - val_precision_m: 0.6631 - val_recall_m: 0.5610\n",
            "Epoch 90/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8537 - acc: 0.6623 - f1_m: 0.6400 - precision_m: 0.6995 - recall_m: 0.5903 - val_loss: 0.9322 - val_acc: 0.6278 - val_f1_m: 0.6090 - val_precision_m: 0.6649 - val_recall_m: 0.5621\n",
            "Epoch 91/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8531 - acc: 0.6628 - f1_m: 0.6406 - precision_m: 0.6998 - recall_m: 0.5911 - val_loss: 0.9324 - val_acc: 0.6277 - val_f1_m: 0.6085 - val_precision_m: 0.6651 - val_recall_m: 0.5611\n",
            "Epoch 92/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8525 - acc: 0.6633 - f1_m: 0.6411 - precision_m: 0.7001 - recall_m: 0.5917 - val_loss: 0.9318 - val_acc: 0.6283 - val_f1_m: 0.6089 - val_precision_m: 0.6650 - val_recall_m: 0.5619\n",
            "Epoch 93/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8519 - acc: 0.6629 - f1_m: 0.6409 - precision_m: 0.7003 - recall_m: 0.5912 - val_loss: 0.9317 - val_acc: 0.6273 - val_f1_m: 0.6095 - val_precision_m: 0.6635 - val_recall_m: 0.5640\n",
            "Epoch 94/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8514 - acc: 0.6630 - f1_m: 0.6414 - precision_m: 0.7000 - recall_m: 0.5923 - val_loss: 0.9312 - val_acc: 0.6278 - val_f1_m: 0.6098 - val_precision_m: 0.6647 - val_recall_m: 0.5636\n",
            "Epoch 95/100\n",
            "98317/98317 [==============================] - 3s 35us/step - loss: 0.8508 - acc: 0.6631 - f1_m: 0.6418 - precision_m: 0.6999 - recall_m: 0.5929 - val_loss: 0.9305 - val_acc: 0.6295 - val_f1_m: 0.6103 - val_precision_m: 0.6680 - val_recall_m: 0.5622\n",
            "Epoch 96/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8503 - acc: 0.6634 - f1_m: 0.6423 - precision_m: 0.7005 - recall_m: 0.5934 - val_loss: 0.9306 - val_acc: 0.6289 - val_f1_m: 0.6097 - val_precision_m: 0.6662 - val_recall_m: 0.5624\n",
            "Epoch 97/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8497 - acc: 0.6639 - f1_m: 0.6423 - precision_m: 0.7007 - recall_m: 0.5933 - val_loss: 0.9298 - val_acc: 0.6293 - val_f1_m: 0.6109 - val_precision_m: 0.6659 - val_recall_m: 0.5647\n",
            "Epoch 98/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8492 - acc: 0.6637 - f1_m: 0.6429 - precision_m: 0.7004 - recall_m: 0.5945 - val_loss: 0.9300 - val_acc: 0.6295 - val_f1_m: 0.6111 - val_precision_m: 0.6659 - val_recall_m: 0.5649\n",
            "Epoch 99/100\n",
            "98317/98317 [==============================] - 3s 36us/step - loss: 0.8487 - acc: 0.6638 - f1_m: 0.6432 - precision_m: 0.7011 - recall_m: 0.5945 - val_loss: 0.9294 - val_acc: 0.6286 - val_f1_m: 0.6113 - val_precision_m: 0.6675 - val_recall_m: 0.5642\n",
            "Epoch 100/100\n",
            "98317/98317 [==============================] - 4s 36us/step - loss: 0.8483 - acc: 0.6643 - f1_m: 0.6434 - precision_m: 0.7010 - recall_m: 0.5949 - val_loss: 0.9292 - val_acc: 0.6290 - val_f1_m: 0.6117 - val_precision_m: 0.6671 - val_recall_m: 0.5651\n",
            "Training Time: 359.94 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHSu-BLOQ-bv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "344a380b-bbfc-4c12-93fa-d89c7bf508e9"
      },
      "source": [
        "#Test Model\n",
        "history_test= Model.fit(X_train_seq_trunc,\n",
        "              y_train_oh,\n",
        "              epochs=num_epochs,\n",
        "              batch_size=128,\n",
        "              verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = Model.evaluate(X_test_seq_trunc, y_test_oh)\n",
        "\n",
        "print('\\nTest accuracy : {0:.2f}%'.format(accuracy*100))\n",
        "print('\\nf1 : {0:.2f}%'.format(f1_score*100))\n",
        "print('\\nprecision : {0:.2f}%'.format(precision*100))\n",
        "print('\\nrecall : {0:.2f}%'.format(recall*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8559 - acc: 0.6614 - f1_m: 0.6404 - precision_m: 0.6979 - recall_m: 0.5920\n",
            "Epoch 2/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8552 - acc: 0.6611 - f1_m: 0.6404 - precision_m: 0.6984 - recall_m: 0.5916\n",
            "Epoch 3/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8545 - acc: 0.6616 - f1_m: 0.6402 - precision_m: 0.6985 - recall_m: 0.5913\n",
            "Epoch 4/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8538 - acc: 0.6616 - f1_m: 0.6407 - precision_m: 0.6985 - recall_m: 0.5922\n",
            "Epoch 5/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8533 - acc: 0.6623 - f1_m: 0.6411 - precision_m: 0.6992 - recall_m: 0.5922\n",
            "Epoch 6/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8527 - acc: 0.6620 - f1_m: 0.6413 - precision_m: 0.6990 - recall_m: 0.5927\n",
            "Epoch 7/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8521 - acc: 0.6624 - f1_m: 0.6413 - precision_m: 0.6994 - recall_m: 0.5926\n",
            "Epoch 8/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8516 - acc: 0.6627 - f1_m: 0.6418 - precision_m: 0.6993 - recall_m: 0.5935\n",
            "Epoch 9/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8511 - acc: 0.6627 - f1_m: 0.6416 - precision_m: 0.6992 - recall_m: 0.5932\n",
            "Epoch 10/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8505 - acc: 0.6630 - f1_m: 0.6423 - precision_m: 0.6998 - recall_m: 0.5939\n",
            "Epoch 11/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8500 - acc: 0.6630 - f1_m: 0.6425 - precision_m: 0.6999 - recall_m: 0.5940\n",
            "Epoch 12/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8495 - acc: 0.6631 - f1_m: 0.6432 - precision_m: 0.7005 - recall_m: 0.5950\n",
            "Epoch 13/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8491 - acc: 0.6636 - f1_m: 0.6433 - precision_m: 0.7004 - recall_m: 0.5952\n",
            "Epoch 14/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8486 - acc: 0.6635 - f1_m: 0.6434 - precision_m: 0.7006 - recall_m: 0.5951\n",
            "Epoch 15/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8482 - acc: 0.6638 - f1_m: 0.6433 - precision_m: 0.7006 - recall_m: 0.5950\n",
            "Epoch 16/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8477 - acc: 0.6639 - f1_m: 0.6436 - precision_m: 0.7003 - recall_m: 0.5957\n",
            "Epoch 17/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8473 - acc: 0.6642 - f1_m: 0.6437 - precision_m: 0.7006 - recall_m: 0.5958\n",
            "Epoch 18/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8469 - acc: 0.6644 - f1_m: 0.6439 - precision_m: 0.7006 - recall_m: 0.5962\n",
            "Epoch 19/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8464 - acc: 0.6645 - f1_m: 0.6443 - precision_m: 0.7005 - recall_m: 0.5968\n",
            "Epoch 20/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8460 - acc: 0.6645 - f1_m: 0.6445 - precision_m: 0.7011 - recall_m: 0.5968\n",
            "Epoch 21/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8457 - acc: 0.6649 - f1_m: 0.6448 - precision_m: 0.7014 - recall_m: 0.5970\n",
            "Epoch 22/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8453 - acc: 0.6650 - f1_m: 0.6451 - precision_m: 0.7012 - recall_m: 0.5977\n",
            "Epoch 23/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8449 - acc: 0.6651 - f1_m: 0.6451 - precision_m: 0.7010 - recall_m: 0.5978\n",
            "Epoch 24/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8445 - acc: 0.6650 - f1_m: 0.6453 - precision_m: 0.7012 - recall_m: 0.5980\n",
            "Epoch 25/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8442 - acc: 0.6652 - f1_m: 0.6453 - precision_m: 0.7011 - recall_m: 0.5981\n",
            "Epoch 26/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8437 - acc: 0.6656 - f1_m: 0.6454 - precision_m: 0.7011 - recall_m: 0.5982\n",
            "Epoch 27/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8434 - acc: 0.6654 - f1_m: 0.6457 - precision_m: 0.7014 - recall_m: 0.5985\n",
            "Epoch 28/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8431 - acc: 0.6660 - f1_m: 0.6456 - precision_m: 0.7015 - recall_m: 0.5984\n",
            "Epoch 29/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8427 - acc: 0.6661 - f1_m: 0.6460 - precision_m: 0.7017 - recall_m: 0.5989\n",
            "Epoch 30/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8424 - acc: 0.6661 - f1_m: 0.6462 - precision_m: 0.7014 - recall_m: 0.5994\n",
            "Epoch 31/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8421 - acc: 0.6660 - f1_m: 0.6466 - precision_m: 0.7017 - recall_m: 0.5999\n",
            "Epoch 32/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8418 - acc: 0.6665 - f1_m: 0.6462 - precision_m: 0.7018 - recall_m: 0.5992\n",
            "Epoch 33/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8415 - acc: 0.6664 - f1_m: 0.6466 - precision_m: 0.7018 - recall_m: 0.5998\n",
            "Epoch 34/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8411 - acc: 0.6666 - f1_m: 0.6466 - precision_m: 0.7019 - recall_m: 0.5998\n",
            "Epoch 35/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8408 - acc: 0.6666 - f1_m: 0.6465 - precision_m: 0.7016 - recall_m: 0.5998\n",
            "Epoch 36/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8405 - acc: 0.6668 - f1_m: 0.6468 - precision_m: 0.7015 - recall_m: 0.6004\n",
            "Epoch 37/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8402 - acc: 0.6667 - f1_m: 0.6469 - precision_m: 0.7018 - recall_m: 0.6003\n",
            "Epoch 38/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8399 - acc: 0.6671 - f1_m: 0.6469 - precision_m: 0.7018 - recall_m: 0.6003\n",
            "Epoch 39/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8397 - acc: 0.6673 - f1_m: 0.6473 - precision_m: 0.7022 - recall_m: 0.6007\n",
            "Epoch 40/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8394 - acc: 0.6671 - f1_m: 0.6473 - precision_m: 0.7020 - recall_m: 0.6009\n",
            "Epoch 41/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8391 - acc: 0.6672 - f1_m: 0.6477 - precision_m: 0.7023 - recall_m: 0.6014\n",
            "Epoch 42/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8388 - acc: 0.6672 - f1_m: 0.6477 - precision_m: 0.7019 - recall_m: 0.6016\n",
            "Epoch 43/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8385 - acc: 0.6679 - f1_m: 0.6478 - precision_m: 0.7026 - recall_m: 0.6013\n",
            "Epoch 44/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8383 - acc: 0.6674 - f1_m: 0.6480 - precision_m: 0.7024 - recall_m: 0.6018\n",
            "Epoch 45/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8380 - acc: 0.6675 - f1_m: 0.6478 - precision_m: 0.7022 - recall_m: 0.6016\n",
            "Epoch 46/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8378 - acc: 0.6678 - f1_m: 0.6480 - precision_m: 0.7024 - recall_m: 0.6018\n",
            "Epoch 47/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8376 - acc: 0.6678 - f1_m: 0.6485 - precision_m: 0.7026 - recall_m: 0.6025\n",
            "Epoch 48/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8373 - acc: 0.6678 - f1_m: 0.6483 - precision_m: 0.7023 - recall_m: 0.6024\n",
            "Epoch 49/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8370 - acc: 0.6683 - f1_m: 0.6484 - precision_m: 0.7025 - recall_m: 0.6025\n",
            "Epoch 50/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8368 - acc: 0.6683 - f1_m: 0.6487 - precision_m: 0.7026 - recall_m: 0.6029\n",
            "Epoch 51/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8366 - acc: 0.6685 - f1_m: 0.6486 - precision_m: 0.7028 - recall_m: 0.6026\n",
            "Epoch 52/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8363 - acc: 0.6685 - f1_m: 0.6490 - precision_m: 0.7027 - recall_m: 0.6033\n",
            "Epoch 53/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8361 - acc: 0.6685 - f1_m: 0.6489 - precision_m: 0.7028 - recall_m: 0.6031\n",
            "Epoch 54/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8359 - acc: 0.6688 - f1_m: 0.6490 - precision_m: 0.7027 - recall_m: 0.6032\n",
            "Epoch 55/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8356 - acc: 0.6687 - f1_m: 0.6490 - precision_m: 0.7026 - recall_m: 0.6033\n",
            "Epoch 56/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8355 - acc: 0.6687 - f1_m: 0.6490 - precision_m: 0.7029 - recall_m: 0.6031\n",
            "Epoch 57/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8352 - acc: 0.6687 - f1_m: 0.6493 - precision_m: 0.7031 - recall_m: 0.6034\n",
            "Epoch 58/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8350 - acc: 0.6689 - f1_m: 0.6495 - precision_m: 0.7029 - recall_m: 0.6040\n",
            "Epoch 59/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8348 - acc: 0.6691 - f1_m: 0.6495 - precision_m: 0.7029 - recall_m: 0.6040\n",
            "Epoch 60/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8346 - acc: 0.6692 - f1_m: 0.6497 - precision_m: 0.7030 - recall_m: 0.6043\n",
            "Epoch 61/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8344 - acc: 0.6693 - f1_m: 0.6498 - precision_m: 0.7032 - recall_m: 0.6044\n",
            "Epoch 62/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8342 - acc: 0.6693 - f1_m: 0.6497 - precision_m: 0.7030 - recall_m: 0.6043\n",
            "Epoch 63/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8340 - acc: 0.6692 - f1_m: 0.6503 - precision_m: 0.7035 - recall_m: 0.6050\n",
            "Epoch 64/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8337 - acc: 0.6693 - f1_m: 0.6501 - precision_m: 0.7032 - recall_m: 0.6048\n",
            "Epoch 65/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8336 - acc: 0.6694 - f1_m: 0.6503 - precision_m: 0.7036 - recall_m: 0.6048\n",
            "Epoch 66/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8334 - acc: 0.6696 - f1_m: 0.6502 - precision_m: 0.7033 - recall_m: 0.6050\n",
            "Epoch 67/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8332 - acc: 0.6695 - f1_m: 0.6504 - precision_m: 0.7034 - recall_m: 0.6052\n",
            "Epoch 68/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8330 - acc: 0.6698 - f1_m: 0.6504 - precision_m: 0.7036 - recall_m: 0.6050\n",
            "Epoch 69/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8328 - acc: 0.6699 - f1_m: 0.6506 - precision_m: 0.7035 - recall_m: 0.6054\n",
            "Epoch 70/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8326 - acc: 0.6698 - f1_m: 0.6505 - precision_m: 0.7035 - recall_m: 0.6054\n",
            "Epoch 71/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8324 - acc: 0.6699 - f1_m: 0.6509 - precision_m: 0.7035 - recall_m: 0.6059\n",
            "Epoch 72/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8323 - acc: 0.6701 - f1_m: 0.6508 - precision_m: 0.7038 - recall_m: 0.6056\n",
            "Epoch 73/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8321 - acc: 0.6700 - f1_m: 0.6510 - precision_m: 0.7038 - recall_m: 0.6060\n",
            "Epoch 74/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8319 - acc: 0.6702 - f1_m: 0.6514 - precision_m: 0.7041 - recall_m: 0.6063\n",
            "Epoch 75/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8317 - acc: 0.6703 - f1_m: 0.6511 - precision_m: 0.7040 - recall_m: 0.6060\n",
            "Epoch 76/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8316 - acc: 0.6698 - f1_m: 0.6512 - precision_m: 0.7041 - recall_m: 0.6061\n",
            "Epoch 77/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8314 - acc: 0.6703 - f1_m: 0.6515 - precision_m: 0.7039 - recall_m: 0.6066\n",
            "Epoch 78/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8312 - acc: 0.6704 - f1_m: 0.6514 - precision_m: 0.7040 - recall_m: 0.6064\n",
            "Epoch 79/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8310 - acc: 0.6703 - f1_m: 0.6514 - precision_m: 0.7038 - recall_m: 0.6065\n",
            "Epoch 80/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8309 - acc: 0.6703 - f1_m: 0.6515 - precision_m: 0.7041 - recall_m: 0.6065\n",
            "Epoch 81/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8307 - acc: 0.6704 - f1_m: 0.6516 - precision_m: 0.7041 - recall_m: 0.6067\n",
            "Epoch 82/100\n",
            "109242/109242 [==============================] - 4s 35us/step - loss: 0.8305 - acc: 0.6708 - f1_m: 0.6516 - precision_m: 0.7042 - recall_m: 0.6067\n",
            "Epoch 83/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8304 - acc: 0.6704 - f1_m: 0.6518 - precision_m: 0.7044 - recall_m: 0.6068\n",
            "Epoch 84/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8303 - acc: 0.6706 - f1_m: 0.6521 - precision_m: 0.7042 - recall_m: 0.6076\n",
            "Epoch 85/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8301 - acc: 0.6706 - f1_m: 0.6520 - precision_m: 0.7043 - recall_m: 0.6072\n",
            "Epoch 86/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8299 - acc: 0.6706 - f1_m: 0.6518 - precision_m: 0.7041 - recall_m: 0.6072\n",
            "Epoch 87/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8298 - acc: 0.6707 - f1_m: 0.6521 - precision_m: 0.7043 - recall_m: 0.6075\n",
            "Epoch 88/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8296 - acc: 0.6710 - f1_m: 0.6521 - precision_m: 0.7045 - recall_m: 0.6073\n",
            "Epoch 89/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8294 - acc: 0.6712 - f1_m: 0.6523 - precision_m: 0.7045 - recall_m: 0.6076\n",
            "Epoch 90/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8293 - acc: 0.6711 - f1_m: 0.6523 - precision_m: 0.7046 - recall_m: 0.6075\n",
            "Epoch 91/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8292 - acc: 0.6711 - f1_m: 0.6524 - precision_m: 0.7045 - recall_m: 0.6078\n",
            "Epoch 92/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8290 - acc: 0.6711 - f1_m: 0.6524 - precision_m: 0.7042 - recall_m: 0.6081\n",
            "Epoch 93/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8288 - acc: 0.6710 - f1_m: 0.6523 - precision_m: 0.7046 - recall_m: 0.6076\n",
            "Epoch 94/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8287 - acc: 0.6713 - f1_m: 0.6526 - precision_m: 0.7046 - recall_m: 0.6082\n",
            "Epoch 95/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8286 - acc: 0.6714 - f1_m: 0.6528 - precision_m: 0.7048 - recall_m: 0.6082\n",
            "Epoch 96/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8284 - acc: 0.6712 - f1_m: 0.6527 - precision_m: 0.7047 - recall_m: 0.6081\n",
            "Epoch 97/100\n",
            "109242/109242 [==============================] - 4s 33us/step - loss: 0.8283 - acc: 0.6713 - f1_m: 0.6529 - precision_m: 0.7051 - recall_m: 0.6083\n",
            "Epoch 98/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8282 - acc: 0.6714 - f1_m: 0.6527 - precision_m: 0.7046 - recall_m: 0.6083\n",
            "Epoch 99/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8280 - acc: 0.6715 - f1_m: 0.6527 - precision_m: 0.7046 - recall_m: 0.6083\n",
            "Epoch 100/100\n",
            "109242/109242 [==============================] - 4s 34us/step - loss: 0.8278 - acc: 0.6716 - f1_m: 0.6530 - precision_m: 0.7048 - recall_m: 0.6087\n",
            "46818/46818 [==============================] - 2s 51us/step\n",
            "\n",
            "Test accuracy : 63.39%\n",
            "\n",
            "f1 : 61.47%\n",
            "\n",
            "precision : 66.58%\n",
            "\n",
            "recall : 57.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ScvJ-HMqgeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e87a440a-4a0b-4240-870e-6f49471c61d2"
      },
      "source": [
        "# Plotting the graphs\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_train.history['acc'], color = 'green', label = 'acc')\n",
        "plt.plot(history_train.history['val_acc'], color = 'red',label = 'train val_acc')\n",
        "plt.title('Train model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncTR2awAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2KsI-YgMMeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "81db63e0-b20e-4ce9-fd65-060496969d7d"
      },
      "source": [
        "plt.plot(history_train.history['loss'], color = 'blue', label = 'loss')\n",
        "plt.plot(history_train.history['val_loss'], color = 'orange',label = 'val_loss')\n",
        "plt.title('Loss in training')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}